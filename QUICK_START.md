# å¿«é€Ÿå¼€å§‹æŒ‡å—

## âš¡ 30 ç§’å¿«é€Ÿå¼€å§‹

```bash
# 1. å®‰è£…ä¾èµ–ï¼ˆä»…éœ€ä¸€æ¬¡ï¼‰
pip3 install -r scripts/requirements.txt

# 2. ç¡®ä¿ Ollama è¿è¡Œ
brew services start ollama

# 3. ç¿»è¯‘ï¼
cd /Volumes/Macintosh\ Extra/Code/keller-sermons
python3 scripts/translate_sermons.py --batch
```

## ğŸ“š å¸¸ç”¨å‘½ä»¤

| å‘½ä»¤ | è¯´æ˜ |
|------|------|
| `python3 scripts/translate_sermons.py --file Sermon_Name` | ç¿»è¯‘å•ä¸ªè®²é“ |
| `python3 scripts/translate_sermons.py --batch` | ç¿»è¯‘æ‰€æœ‰è®²é“ |
| `python3 scripts/translate_sermons.py --file Sermon_Name --backend ollama` | å¼ºåˆ¶ä½¿ç”¨ Ollama |
| `python3 scripts/translate_sermons.py --file Sermon_Name --backend claude` | å¼ºåˆ¶ä½¿ç”¨ Claude |
| `python3 scripts/translate_sermons.py --help` | æ˜¾ç¤ºå¸®åŠ© |

## ğŸ¯ é¢„æœŸç»“æœ

```
Translation backend: ollama
  Translating Sermon_Name... DONE
Translated Sermon_Name
```

## âœ… éªŒè¯å®‰è£…

```bash
# æ£€æŸ¥ Ollama
ollama list | grep qwen2.5

# æ£€æŸ¥ Python ä¾èµ–
python3 -c "import anthropic, openai, requests; print('âœ“ All OK')"

# æ£€æŸ¥è„šæœ¬
python3 -m py_compile scripts/translate_sermons.py && echo "âœ“ Syntax OK"
```

## ğŸš¨ å¸¸è§é—®é¢˜

### "Connection refused" é”™è¯¯
```bash
brew services start ollama
```

### "Model not found" é”™è¯¯
```bash
ollama pull qwen2.5:7b-instruct-q8_0
```

### ç¿»è¯‘å¾ˆæ…¢
- æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨ï¼š`top` æˆ– Activity Monitor
- å¦‚æœ CPU ä½¿ç”¨ç‡ä½ï¼Œå¯èƒ½åœ¨ä½¿ç”¨ CPU è€Œé GPU
- è€ƒè™‘ä½¿ç”¨ `--backend claude` ä½œä¸ºå¿«é€Ÿå¤‡é€‰

## ğŸ“– å®Œæ•´æ–‡æ¡£

- **OLLAMA_INTEGRATION_GUIDE.md** - è¯¦ç»†æŒ‡å—
- **FORMATTING_PRESERVATION.md** - æ ¼å¼ä¿ç•™è¯´æ˜
- **IMPLEMENTATION_SUMMARY.md** - å®æ–½æ€»ç»“

## ğŸ’¡ æœ€ä½³å®è·µ

1. é¦–æ¬¡è¿è¡Œå‰ç¡®ä¿ Ollama å·²å¯åŠ¨
2. å¯¹å…³é”®è®²é“ä½¿ç”¨ `--backend claude` è·å¾—æœ€ä¼˜è´¨é‡
3. å®šæœŸæ£€æŸ¥ç¿»è¯‘è´¨é‡ï¼Œä¸æ»¡æ„çš„æ®µè½å¯æ‰‹åŠ¨è°ƒæ•´
4. ä¿æŒ git ä»“åº“æ›´æ–°ï¼Œä¾¿äºç‰ˆæœ¬æ§åˆ¶

---

**æ›´å¤šé—®é¢˜ï¼Ÿ** æŸ¥çœ‹ OLLAMA_INTEGRATION_GUIDE.md çš„"å¸¸è§é—®é¢˜"ç« èŠ‚ã€‚
